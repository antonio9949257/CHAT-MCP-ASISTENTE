# Proyecto MCP Real: Gemini con Next.js y Tool Calling

Este proyecto es una demostraciÃ³n de cÃ³mo implementar el patrÃ³n Model-Client-Proxy (MCP) utilizando Next.js (para frontend y backend) y el SDK oficial de Google Gemini para la funcionalidad de `tool calling` (llamada a herramientas).

## ğŸš€ PropÃ³sito del Proyecto

El objetivo principal es ilustrar cÃ³mo un modelo de lenguaje (Gemini) puede interactuar con funciones personalizadas (herramientas) definidas en tu backend para obtener informaciÃ³n o realizar acciones que el modelo por sÃ­ mismo no puede hacer. Esto simula un "servidor MCP" donde tu aplicaciÃ³n ejecuta las llamadas a herramientas solicitadas por el modelo.

## âœ¨ Funcionalidades Implementadas

El asistente de chat en este proyecto puede:

1.  **Obtener InformaciÃ³n de Productos:** Consulta datos de productos ficticios (precio, stock) usando la herramienta `getProductInfo`.
    *   Ej: "Â¿CuÃ¡nto cuesta laptop-01?", "Dime el stock de mouse-02."
2.  **Sumar NÃºmeros:** Realiza operaciones matemÃ¡ticas bÃ¡sicas usando la herramienta `addNumbers`.
    *   Ej: "Suma 5 y 3.", "Â¿CuÃ¡nto es 100 mÃ¡s 20?"
3.  **Obtener InformaciÃ³n del Sistema Operativo:** Extrae datos reales y detallados del sistema donde se ejecuta el servidor (plataforma, arquitectura, memoria, CPU, hostname, usuario, etc.) usando la herramienta `getSystemInfo`.
    *   Ej: "Â¿QuÃ© sistema operativo estÃ¡s usando?", "Dime el nombre de host.", "Â¿QuiÃ©n es el usuario actual?", "Dame toda la informaciÃ³n del sistema."
4.  **Obtener Hora y Fecha Actual:** Consulta la hora y fecha real del sistema usando la herramienta `getCurrentTime`.
    *   Ej: "Â¿QuÃ© hora es?", "Dime la fecha de hoy."

## ğŸ› ï¸ TecnologÃ­as Utilizadas

*   **Next.js 14+:** Framework de React para el desarrollo full-stack (App Router).
*   **TypeScript:** Para un desarrollo mÃ¡s robusto y con tipado estÃ¡tico.
*   **Tailwind CSS:** Para estilos rÃ¡pidos y responsivos.
*   **daisyUI:** Plugin de Tailwind CSS para componentes de UI pre-estilizados.
*   **Google Gemini API (`@google/generative-ai`):** SDK oficial para interactuar con los modelos de Gemini.

## âš™ï¸ ConfiguraciÃ³n y EjecuciÃ³n

Sigue estos pasos para poner el proyecto en marcha:

### 1. Clonar el Repositorio (o crear la estructura si lo hiciste manualmente)

Si estÃ¡s siguiendo los pasos de creaciÃ³n manual, asegÃºrate de tener la estructura de archivos y el `package.json` configurados como se indicÃ³.

### 2. Instalar Dependencias

Navega al directorio raÃ­z del proyecto (`mcp_real`) e instala las dependencias:

```bash
npm install
```

### 3. Configurar la Clave de API de Google Gemini

Necesitas una clave de API de Google Gemini. Si no tienes una, puedes generarla en [Google AI Studio](https://aistudio.google.com/).

Crea un archivo `.env.local` en la raÃ­z del proyecto (`mcp_real/`) y aÃ±ade tu clave:

```
GOOGLE_API_KEY="TU_CLAVE_API_DE_GEMINI"
```

**Â¡Importante!** Reemplaza `TU_CLAVE_API_DE_GEMINI` con tu clave real.

### 4. Ejecutar el Servidor de Desarrollo

```bash
npm run dev
```

El servidor se iniciarÃ¡ en `http://localhost:3000`. Abre esta URL en tu navegador para interactuar con el asistente de chat.

## ğŸ“‚ Estructura del Proyecto

```
mcp_real/
â”œâ”€â”€ .env.local
â”œâ”€â”€ .gitignore
â”œâ”€â”€ next.config.mjs
â”œâ”€â”€ package.json
â”œâ”€â”€ postcss.config.mjs
â”œâ”€â”€ README.md
â”œâ”€â”€ tailwind.config.js
â”œâ”€â”€ tsconfig.json
â””â”€â”€ src/
    â”œâ”€â”€ app/
    â”‚   â”œâ”€â”€ api/
    â”‚   â”‚   â””â”€â”€ chat/
    â”‚   â”‚       â””â”€â”€ route.ts  # Backend: Maneja la lÃ³gica de Gemini y tool calling
    â”‚   â”œâ”€â”€ globals.css     # Estilos globales de Tailwind
    â”‚   â”œâ”€â”€ layout.tsx      # Layout principal de Next.js
    â”‚   â””â”€â”€ page.tsx        # Frontend: Interfaz de usuario del chat
    â””â”€â”€ lib/
        â””â”€â”€ tools.ts      # ImplementaciÃ³n de las funciones (herramientas) del backend
```

## ğŸ’¡ CÃ³mo Funciona el Tool Calling (MCP)

1.  **DefiniciÃ³n de Herramientas:** En `src/app/api/chat/route.ts`, se definen las herramientas (`getProductInfo`, `addNumbers`, `getSystemInfo`, `getCurrentTime`) con su nombre, descripciÃ³n y parÃ¡metros esperados. Estas definiciones se pasan al modelo Gemini.
2.  **IntenciÃ³n del Usuario:** El usuario escribe una pregunta en el frontend (ej. "Â¿CuÃ¡nto cuesta laptop-01?").
3.  **EnvÃ­o al Backend:** El frontend envÃ­a la pregunta (y el historial del chat) a la API de Next.js (`/api/chat`).
4.  **Razonamiento del Modelo:** El modelo Gemini recibe la pregunta y el historial. Si determina que una de las herramientas definidas puede responder a la pregunta, genera un `tool_call` (una instrucciÃ³n para llamar a una funciÃ³n especÃ­fica con ciertos parÃ¡metros).
5.  **EjecuciÃ³n de la Herramienta (MCP):** El backend intercepta este `tool_call`. En lugar de que el modelo ejecute la funciÃ³n directamente, el backend (simulando el "servidor MCP") llama a la implementaciÃ³n real de esa funciÃ³n (definida en `src/lib/tools.ts`).
6.  **Respuesta de la Herramienta:** La funciÃ³n ejecutada devuelve un resultado (ej. `{ price: 1200 }`).
7.  **ReenvÃ­o al Modelo:** El backend envÃ­a este resultado de vuelta al modelo Gemini como un `functionResponse`.
8.  **GeneraciÃ³n de Respuesta Final:** Con la informaciÃ³n de la herramienta, el modelo genera una respuesta en lenguaje natural para el usuario (ej. "La laptop-01 cuesta $1200.").
9.  **VisualizaciÃ³n en Frontend:** El backend envÃ­a esta respuesta final al frontend para que se muestre al usuario.

Este flujo permite que el modelo extienda sus capacidades mÃ¡s allÃ¡ de su conocimiento entrenado, interactuando con sistemas externos de manera controlada y segura.
